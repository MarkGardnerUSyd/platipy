{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "base_url = 'http://127.0.0.1:8001'\n",
    "api_key = ''\n",
    "\n",
    "algorithm_name = 'Pinnacle Export'\n",
    "api_dicom_location = '{0}/api/dicomlocation'.format(base_url)\n",
    "api_dataset = '{0}/api/dataset'.format(base_url)\n",
    "api_dataset_ready = '{0}/api/dataset/ready'.format(base_url)\n",
    "api_data_object = '{0}/api/dataobject'.format(base_url)\n",
    "api_trigger = '{0}/api/trigger'.format(base_url)\n",
    "api_algorithm = '{0}/api/algorithm'.format(base_url)\n",
    "api_download = '{0}/api/dataobject/download'.format(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the algorithm and the default settings\n",
    "algorithm = None\n",
    "r = requests.get(api_algorithm, headers={'API_KEY': api_key})\n",
    "if r.status_code == 200:\n",
    "    for a in r.json():\n",
    "        pprint(a)\n",
    "        if a['name'] == algorithm_name:\n",
    "            algorithm = a\n",
    "    print(\"\")\n",
    "    print(\"Look's Good!\")\n",
    "else:\n",
    "    print(\"Oops, something went wrong. Ensure the service is running at the base_url configured and that the API Key has been generated and set in api_key.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we already have the Orthanc Dicom Location, if not lets add it\n",
    "orthanc_location = None\n",
    "r = requests.get(api_dicom_location, headers={'API_KEY': api_key})\n",
    "for d in r.json():\n",
    "    if d['name'] == 'Orthanc':\n",
    "        orthanc_location = d\n",
    "        break\n",
    "        \n",
    "if not orthanc_location:\n",
    "    # If we didn't find the Orthanc location then lets add it now\n",
    "    data = {'name': 'Orthanc',\n",
    "           'host': '127.0.0.1',\n",
    "           'port': 4242,\n",
    "           'ae_title': 'ORTHANC'}\n",
    "    r = requests.post(api_dicom_location, headers={'API_KEY': api_key}, data=data)\n",
    "    \n",
    "    if r.status_code >= 200 and r.status_code < 300:\n",
    "        print('Added Orthanc Location')\n",
    "        orthanc_location = r.json()\n",
    "        \n",
    "pprint(orthanc_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Dataset\n",
    "dataset = None\n",
    "data = {'to_dicom_location': orthanc_location['id']}\n",
    "data = {}\n",
    "r = requests.post(api_dataset, headers={'API_KEY': api_key}, data=data)\n",
    "if r.status_code >= 200:\n",
    "        dataset = r.json()\n",
    "        \n",
    "pprint(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Pinnacle Tar archive to the dataset\n",
    "path_to_tar = f'../tests/data/pinnacle/test_pinnacle_16.0.tar.gz'\n",
    "data_object = None\n",
    "\n",
    "# Get the Series UID of this Data Object\n",
    "with open(path_to_tar,'rb') as file:\n",
    "    \n",
    "    meta_data = {\n",
    "        \"patient_path\": \"Institution_2812/Mount_0/Patient_16218\", # The path to the patient folder within the tar archive\n",
    "        \"plan_name\": \"Plan_2\", # The name of the plan to export in pinnacle (optional, default use first),\n",
    "        \"trial\": \"\", # The name of the trial to export in the plan (optional, default: use FINAL or first),\n",
    "        'some_test_data': \"TESTING 1234\"\n",
    "    }\n",
    "\n",
    "    data = {'dataset': dataset['id'],\n",
    "            'type': 'FILE',\n",
    "            'meta_data': json.dumps(meta_data),\n",
    "            'file_name': 'test_pinnacle_16.0.tar.gz'}\n",
    "    \n",
    "    r = requests.post(api_data_object, headers={'API_KEY': api_key}, data=data, files={'file_data':file})\n",
    "    if r.status_code >= 200:\n",
    "            data_object = r.json()\n",
    "        \n",
    "pprint(data_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the algorithm and the default settings\n",
    "algorithm = None\n",
    "r = requests.get(api_algorithm, headers={'API_KEY': api_key})\n",
    "if r.status_code == 200:\n",
    "    for a in r.json():\n",
    "        if algorithm_name in a['name']:\n",
    "            algorithm = a\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger the algorithm with our dataset containing the data object\n",
    "data={'dataset': dataset['id'],\n",
    "     'algorithm': algorithm['name']}\n",
    "r = requests.post(api_trigger, headers={'API_KEY': api_key}, data=data)\n",
    "\n",
    "if r.status_code == 200:\n",
    "    # Poll the URL given to determine the progress of the task\n",
    "    poll_url = '{0}{1}'.format(base_url, r.json()['poll'])\n",
    "    \n",
    "    while(1):\n",
    "        r = requests.get(poll_url, headers={'API_KEY': api_key})\n",
    "        status = r.json()\n",
    "        print(status)\n",
    "\n",
    "        if status['state'] == 'SUCCESS' or status['state'] == 'FAILURE':\n",
    "            break\n",
    "\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    print(r.json())\n",
    "    \n",
    "print('Algorithm Processing Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the dataset objects output\n",
    "r = requests.get('{0}/{1}'.format(api_dataset, dataset['id']), headers={'API_KEY': api_key})\n",
    "if r.status_code == 200:\n",
    "    dataset = r.json()\n",
    "    pprint(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
