{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "from pprint import pprint\n",
    "import SimpleITK as sitk\n",
    "\n",
    "base_url = 'http://127.0.0.1:8001'\n",
    "api_key = ''\n",
    "\n",
    "algorithm_name = \"\n",
    "\"\n",
    "api_dicom_location = '{0}/api/dicomlocation'.format(base_url)\n",
    "api_dataset = '{0}/api/dataset'.format(base_url)\n",
    "api_dataset_ready = '{0}/api/dataset/ready'.format(base_url)\n",
    "api_data_object = '{0}/api/dataobject'.format(base_url)\n",
    "api_trigger = '{0}/api/trigger'.format(base_url)\n",
    "api_algorithm = '{0}/api/algorithm'.format(base_url)\n",
    "api_download = '{0}/api/dataobject/download'.format(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the algorithm and the default settings\n",
    "algorithm = None\n",
    "r = requests.get(api_algorithm, headers={'API_KEY': api_key})\n",
    "if r.status_code == 200:\n",
    "    for a in r.json():\n",
    "        pprint(a)\n",
    "        if a['name'] == algorithm_name:\n",
    "            algorithm = a\n",
    "    print(\"\")\n",
    "    print(\"Look's Good!\")\n",
    "else:\n",
    "    print(\"Oops, something went wrong. Ensure the service is running at the base_url configured and that the API Key has been generated and set in api_key.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Dataset\n",
    "dataset = None\n",
    "data = {}\n",
    "r = requests.post(api_dataset, headers={'API_KEY': api_key}, data=data)\n",
    "if r.status_code >= 200:\n",
    "        dataset = r.json()\n",
    "        \n",
    "pprint(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the phantom dicom data, both as primary and secondary\n",
    "path_to_dicom = f\"../../dicom/data/phantom/CT\"\n",
    "load_path = sitk.ImageSeriesReader().GetGDCMSeriesFileNames(path_to_dicom)\n",
    "image = sitk.ReadImage(load_path)\n",
    "\n",
    "tmp_dir = tempfile.mkdtemp()\n",
    "tmp_file = os.path.join(tmp_dir, \"img.nii.gz\")\n",
    "sitk.WriteImage(image, tmp_file)\n",
    "\n",
    "data_object = None\n",
    "\n",
    "# Add the primary image\n",
    "with open(tmp_file,'rb') as file:\n",
    "\n",
    "    data = {'dataset': dataset['id'],\n",
    "            'type': 'FILE',\n",
    "            'meta_data': json.dumps({\"type\": \"primary\",}),\n",
    "            'file_name': 'primary.nii.gz'}\n",
    "    \n",
    "    r = requests.post(api_data_object, headers={'API_KEY': api_key}, data=data, files={'file_data':file})\n",
    "    if r.status_code >= 200:\n",
    "            primary_data_object = r.json()\n",
    "            \n",
    "# Add a child struct in which to find points for primary\n",
    "path_to_struct = f\"../../dicom/data/phantom/masks/Test_MANDIBLE_PRI.nii.gz\"\n",
    "with open(path_to_struct,'rb') as file:\n",
    "\n",
    "    data = {'dataset': dataset['id'],\n",
    "            'type': 'FILE',\n",
    "            \"parent\": primary_data_object['id'],\n",
    "            'meta_data': json.dumps({\"type\": \"contour\",\"name\": \"Struct_1\"}),\n",
    "            'file_name': 'struct.nii.gz'}\n",
    "    \n",
    "    r = requests.post(api_data_object, headers={'API_KEY': api_key}, data=data, files={'file_data':file})\n",
    "    if r.status_code >= 200:\n",
    "            secondary_contour_data_object = r.json()\n",
    "            \n",
    "# Add the secondary Image\n",
    "with open(tmp_file,'rb') as file:\n",
    "\n",
    "    data = {'dataset': dataset['id'],\n",
    "            'type': 'FILE',\n",
    "            'meta_data': json.dumps({\"type\": \"secondary\",}),\n",
    "            'file_name': 'secondary.nii.gz'}\n",
    "    \n",
    "    r = requests.post(api_data_object, headers={'API_KEY': api_key}, data=data, files={'file_data':file})\n",
    "    if r.status_code >= 200:\n",
    "            secondary_data_object = r.json()\n",
    "\n",
    "\n",
    "            \n",
    "# Add a child struct in which to find points for primary\n",
    "path_to_struct = f\"../../dicom/data/phantom/masks/Test_MANDIBLE_PRI.nii.gz\"\n",
    "with open(path_to_struct,'rb') as file:\n",
    "\n",
    "    data = {'dataset': dataset['id'],\n",
    "            'type': 'FILE',\n",
    "            \"parent\": secondary_data_object['id'],\n",
    "            'meta_data': json.dumps({\"type\": \"contour\",\"name\": \"Struct_1\"}),\n",
    "            'file_name': 'struct.nii.gz'}\n",
    "    \n",
    "    r = requests.post(api_data_object, headers={'API_KEY': api_key}, data=data, files={'file_data':file})\n",
    "    if r.status_code >= 200:\n",
    "            primary_contour_data_object = r.json()\n",
    "            \n",
    "# Take a look at the dataset objects output\n",
    "r = requests.get('{0}/{1}'.format(api_dataset, dataset['id']), headers={'API_KEY': api_key})\n",
    "if r.status_code == 200:\n",
    "    dataset = r.json()\n",
    "    pprint(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the algorithm and the default settings\n",
    "algorithm = None\n",
    "r = requests.get(api_algorithm, headers={'API_KEY': api_key})\n",
    "if r.status_code == 200:\n",
    "    for a in r.json():\n",
    "        if algorithm_name in a['name']:\n",
    "            algorithm = a\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = algorithm['default_settings']\n",
    "settings['includePointsMode'] = \"BOUNDINGBOX\"\n",
    "settings['intensityRange'] = [-200, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger the algorithm with our dataset containing the data object\n",
    "data={'dataset': dataset['id'],\n",
    "     'algorithm': algorithm['name'],\n",
    "     'config': json.dumps(settings)}\n",
    "r = requests.post(api_trigger, headers={'API_KEY': api_key}, data=data)\n",
    "\n",
    "if r.status_code == 200:\n",
    "    # Poll the URL given to determine the progress of the task\n",
    "    poll_url = '{0}{1}'.format(base_url, r.json()['poll'])\n",
    "    \n",
    "    while(1):\n",
    "        r = requests.get(poll_url, headers={'API_KEY': api_key})\n",
    "        status = r.json()\n",
    "        print(status)\n",
    "\n",
    "        if status['state'] == 'SUCCESS' or status['state'] == 'FAILURE':\n",
    "            break\n",
    "\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    print(r.json())\n",
    "    \n",
    "print('Algorithm Processing Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the dataset objects output\n",
    "r = requests.get('{0}/{1}'.format(api_dataset, dataset['id']), headers={'API_KEY': api_key})\n",
    "if r.status_code == 200:\n",
    "    dataset = r.json()\n",
    "    pprint(dataset)\n",
    "\n",
    "    for d in dataset['output_data_objects']:\n",
    "        r = requests.get('{0}/{1}'.format(api_download, d['id']), headers={'API_KEY': api_key})\n",
    "        filename = r.headers['Content-Disposition'].split('filename=')[1]\n",
    "        print('Downloading to: {0}'.format(filename))\n",
    "        open(filename, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds = pd.read_csv(\"primary_Struct_1_match.csv\", header=None)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
